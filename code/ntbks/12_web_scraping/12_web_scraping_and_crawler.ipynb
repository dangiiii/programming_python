{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12 Web scraping\n",
    "\"Beautiful Soup is a Python library for pulling data out of HTML and XML files. It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree. It commonly saves programmers hours or days of work.\"[[1]](https://beautiful-soup-4.readthedocs.io/en/latest/)<br><br>\n",
    "The easiest way to install Beautiful Soup is via pip: <i>pip install beautifulsoup4</i><br>\n",
    "The requests package [[2]](https://pypi.org/project/requests/), which is a simple HTTP library to handle HTTP requests, can also be installed via pip: <i>pip install requests</i><br><br>\n",
    "This notebook contains some useful examples on how to use bs4, but you can find alot more additional information on installation process, features and everything else you might need for working with this package [here](https://beautiful-soup-4.readthedocs.io/en/latest/).\n",
    "\n",
    "### Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the request package to get the contents of the given URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://realpython.github.io/fake-jobs/\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "print(page.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different types of parsers available for bs4 (like html, xml etc.). We are utilizing the html.parser here as we are dealing with webpages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "print(f\"type(soup): {type(soup)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(soup)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using find() you will get all the content in the page which comes after your search target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = soup.find(id=\"ResultsContainer\")\n",
    "print(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The prettify() method will turn a Beautiful Soup parse tree into a nicely formatted Unicode string, with a separate line for each tag and each string:\"[[3]](https://beautiful-soup-4.readthedocs.io/en/latest/#making-the-soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(results.prettify())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return the first element of a specific HTML-tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.div"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return all elements with a specific HTML-tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list(results.find_all('p'))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return all elements with a specific HTML-tag and class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(list(results.find_all('p', class_=\"location\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(results.find_all('p'))[0])\n",
    "print()\n",
    "print(list(results.find_all('p'))[1])\n",
    "print()\n",
    "print(list(results.find_all('p'))[2].text)\n",
    "print()\n",
    "print(list(results.find_all('p'))[3].text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find all job offers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the page we are looking at is all about fake job offers, let's see what they got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_elements = results.find_all(\"div\", class_=\"card-content\")\n",
    "print(job_elements)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better and clearer overview we can print the job_elements in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job_element in job_elements:\n",
    "    print(job_element, end=\"\\n\"*2)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple different job_elements as seen above, each of them representing one open job offer. We now want to extract only the inforamtion which are relevant to us, in this case the job title, company name and job location. For this we iterate over all found jobs and then search for the specific HTML elements we are looking for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for job_element in job_elements:\n",
    "    print(type(job_element))\n",
    "    title_element = job_element.find(\"h2\", class_=\"title\")\n",
    "    company_element = job_element.find(\"h3\", class_=\"company\")\n",
    "    location_element = job_element.find(\"p\", class_=\"location\")\n",
    "    print(title_element)\n",
    "    print(company_element)\n",
    "    print(location_element)\n",
    "    print()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract text\n",
    "We did find the elements we were looking for, yet they still contain unnecessary information like the HTML syntax. By using \".text\" for each retrieved element we can get rid of the HTML syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for job_element in job_elements:\n",
    "    title_element = job_element.find(\"h2\", class_=\"title\")\n",
    "    company_element = job_element.find(\"h3\", class_=\"company\")\n",
    "    location_element = job_element.find(\"p\", class_=\"location\")\n",
    "    print(title_element.text)\n",
    "    print(company_element.text)\n",
    "    print(location_element.text)\n",
    "    print()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is still not exactly as we would like it as the returned texts are oftentimes not formatted correctly or contain spaces, like seen above. In order to strip away the empty spaces you have to slightly modify your code like follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for job_element in job_elements:\n",
    "    title_element = job_element.find(\"h2\", class_=\"title\")\n",
    "    company_element = job_element.find(\"h3\", class_=\"company\")\n",
    "    location_element = job_element.find(\"p\", class_=\"location\")\n",
    "    # print(len(title_element.text))\n",
    "    # print(len(title_element.text.strip()))\n",
    "    print(title_element.text.strip())\n",
    "    print(company_element.text.strip())\n",
    "    print(location_element.text.strip())\n",
    "    print()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are looking for a specific job offer you can again use the find_all() method to return all elements which exactly contain a certain string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_jobs = results.find_all(\"h2\", string=\"Python\")\n",
    "print(f\"python_jobs: {python_jobs}\")\n",
    "\n",
    "python_jobs = results.find_all(\"h2\", string=\"Software Engineer (Python)\")\n",
    "print(f\"python_jobs: {python_jobs}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this feature even more useful you can utilize a lambda function to be more flexible when it comes to the evaluation of search terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_jobs = results.find_all(\n",
    "    \"h2\", string=lambda text: \"python\" in text.lower()\n",
    ")\n",
    "print(f\"python_jobs: {python_jobs}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand found elements\n",
    "The following command allows you to return the parents of your chosen element(s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_jobs = results.find_all(\n",
    "    \"h2\", string=lambda text: \"python\" in text.lower()\n",
    ")\n",
    "\n",
    "python_job_elements = [\n",
    "    h2_element.parent.parent.parent for h2_element in python_jobs\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for el in python_job_elements:\n",
    "    print(el)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting URLs\n",
    "Sometimes you may not just want to extract the text from found elements, but also URLs contained in them. Using .text will not deliver what we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for job_element in python_job_elements:\n",
    "    # -- snip --\n",
    "    links = job_element.find_all(\"a\")\n",
    "    for link in links:\n",
    "        print(link.text.strip())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using [\"href\"] we can directly access the hyperlink information contained inside the HTML element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for job_element in python_job_elements:\n",
    "    # -- snip --\n",
    "    links = job_element.find_all(\"a\")\n",
    "    for link in links:\n",
    "        link_url = link[\"href\"]\n",
    "        print(f\"Apply here: {link_url}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job_element in python_job_elements:\n",
    "    # -- snip --\n",
    "    links = job_element.find_all(\"a\")\n",
    "    for link in links:\n",
    "        link_url = link[\"href\"]\n",
    "        if link_url==\"https://www.realpython.com\":\n",
    "            continue\n",
    "        print(f\"Apply here: {link_url}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
